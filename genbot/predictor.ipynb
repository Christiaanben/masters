{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81770ef3-c622-4644-99e8-f28796faaa57",
   "metadata": {},
   "source": [
    "# Intent Predictor\n",
    "\n",
    "In the rapidly evolving landscape of conversational AI, understanding and predicting user intent has emerged as a paramount task. A conversation, akin to a dance of words, is a sequence where each participant's response is predicated not just on the last statement, but on the flow and context of the entire conversation. Given the multilabel nature of many intents, predicting them requires nuanced, sequence-based models that can capture the intricacies of conversational context.\r\n",
    "\r\n",
    "This notebook aims to tackle the fascinating challenge of intent prediction based on the sequence of previous intents in a conversation. Our objective is to predict the intent with which we should respond, grounded in the series of multilabel intents we classified up until a given poin\n",
    "\n",
    "## Data\n",
    "\n",
    "The dataset employed is derived from the conversational exchanges up to this point. It's imperative to note that while the data remains consistent, its preparation and representation will be adapted to suit the requirements of our model and task.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "We've chosen the Gated Recurrent Unit (GRU), a recurrent neural network architecture, for this task. The GRU, with its ability to capture long-term dependencies in sequences, stands as an apt choice for the sequence-based nature of our problem. Additionally, the GRU's efficiency and less complex structure compared to other recurrent architectures make it a promising candidate.\n",
    "\n",
    "## Development Environment\n",
    "\n",
    "To streamline our development process and reduce boilerplate code, we'll be leveraging pytorch-lightning. Specifically, our model will be constructed as a pytorch-lightning Module, and the data handling, preprocessing, and loading will be encapsulated within a pytorch-lightning DataModule. This choice not only enhances the modularity and readability of our code but also facilitates easier scalability and experimentation.\n",
    "\n",
    "In the sections that follow, we'll delve deep into data preparation, model architecture, training, evaluation, and inference. Let's embark on this exciting journey of understanding and predicting conversational intent.t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7c017a7-57f6-4885-a28f-6b76c0ee6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from sklearn.model_selection import train_test_split # scikit-learn\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ea1851-2313-4fee-9f7f-e62bad1dadce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1bf8701ee90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup & Configurations (constants, seeds, and devices)\n",
    "RANDOM_SEED = 69\n",
    "DATASET_FILENAME = '../data/clean/customer_support_twitter_full.json'\n",
    "SEQUENCE_LENGTH = 3\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d68ac3a7-9c36-4b52-96d6-6ca4b0416d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation Count: 1001\n",
      "Label Counts: ['Acknowledgement', 'Call Center Inquiry', 'Check Version/Details', 'Direct to DM', 'Provide Information', 'Question', 'Report Problem', 'Troubleshooting', 'URL Share']\n",
      "Sample Conversation:\n",
      "[\n",
      "  {\n",
      "    \"id\": 698,\n",
      "    \"text\": \"@AppleSupport  URL\",\n",
      "    \"authored\": false,\n",
      "    \"intents\": [\n",
      "      \"URL Share\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 696,\n",
      "    \"text\": \"USERNAME We're here for you. Which version of the iOS are you running? Check from Settings > General > About.\",\n",
      "    \"authored\": true,\n",
      "    \"intents\": [\n",
      "      \"Question\",\n",
      "      \"Provide Information\",\n",
      "      \"Check Version/Details\",\n",
      "      \"Acknowledgement\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 697,\n",
      "    \"text\": \"@AppleSupport The newest update. I made sure to download it yesterday.\",\n",
      "    \"authored\": false,\n",
      "    \"intents\": [\n",
      "      \"Provide Information\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 699,\n",
      "    \"text\": \"USERNAME Lets take a closer look into this issue. Select the following link to join us in a DM and we'll go from there. URL\",\n",
      "    \"authored\": true,\n",
      "    \"intents\": [\n",
      "      \"Report Problem\",\n",
      "      \"Direct to DM\",\n",
      "      \"URL Share\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Define PyTorch Dataset\n",
    "class PredictorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Define PyTorch Lightning DataModule\n",
    "class PredictorDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, filename: str, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "        self.conversations = self._load_conversations(filename)\n",
    "        self.batch_size = batch_size\n",
    "        labels = set()\n",
    "        for conversation in self.conversations:\n",
    "            for message in conversation:\n",
    "                for intent in message.get('intents'):\n",
    "                    labels.add(intent)\n",
    "        self.labels = sorted(list(labels))\n",
    "        data = []\n",
    "        for conversation in self.conversations:\n",
    "            for j, message in enumerate(conversation):\n",
    "                if message.get('authored') and j > 0:\n",
    "                    inputs = torch.stack([self._get_label(m.get('intents')) for m in conversation[:j]][-SEQUENCE_LENGTH:])\n",
    "                    padding_needed = max(SEQUENCE_LENGTH - inputs.shape[0], 0)\n",
    "                    padded_inputs = F.pad(inputs, (0, 0, padding_needed, 0))\n",
    "                    target = self._get_label(message.get('intents'))\n",
    "                    data.append((padded_inputs, target))\n",
    "        \n",
    "        # Split the data into 80% train, 10% validation, and 10% test\n",
    "        train_data, temp_data = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)\n",
    "        val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=RANDOM_SEED)\n",
    "\n",
    "        # Setup datasets\n",
    "        self.train_dataset = PredictorDataset(train_data)\n",
    "        self.val_dataset = PredictorDataset(val_data)\n",
    "        self.test_dataset = PredictorDataset(test_data)\n",
    "        \n",
    "\n",
    "    def _get_label(self, intents: list[str]):\n",
    "        label = torch.zeros(len(self.labels))\n",
    "        for intent in intents:\n",
    "            label[self.labels.index(intent)] = 1\n",
    "        return label\n",
    "                \n",
    "\n",
    "    @staticmethod\n",
    "    def _load_conversations(filename):\n",
    "        with open(filename) as file:\n",
    "            conversations = json.load(file)\n",
    "        return conversations\n",
    "\n",
    "    @property\n",
    "    def stats(self):\n",
    "        return '\\n'.join([\n",
    "            f'Conversation Count: {len(self.conversations)}',\n",
    "            f'Label Counts: {self.labels}',\n",
    "            f'Sample Conversation:\\n{json.dumps(self.conversations[0], indent=2)}',\n",
    "        ])\n",
    "\n",
    "    @property\n",
    "    def n_labels(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "dm = PredictorDataModule(DATASET_FILENAME)\n",
    "print(dm.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af5cf7ff-16b9-4902-adb4-2e521927a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Loading & Configuration\n",
    "class PredictorModel(pl.LightningModule):\n",
    "    HIDDEN_SIZE = 32\n",
    "    DROPOUT = 0.2\n",
    "    \n",
    "    def __init__(self, n_labels):\n",
    "        super().__init__()\n",
    "        # Layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_labels,\n",
    "            hidden_size=self.HIDDEN_SIZE,\n",
    "            num_layers=1,\n",
    "            dropout=self.DROPOUT,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.HIDDEN_SIZE, n_labels)\n",
    "        # Metrics\n",
    "        self.accuracy = torchmetrics.classification.MultilabelAccuracy(\n",
    "            num_labels=n_labels,\n",
    "        )\n",
    "        self.f1_score = torchmetrics.classification.MultilabelF1Score(\n",
    "            num_labels=n_labels,\n",
    "            average='micro',\n",
    "        )\n",
    "        self.hamming_loss = torchmetrics.classification.MultilabelHammingDistance(\n",
    "            num_labels=n_labels,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # GRU\n",
    "        output, _ = self.gru(x)\n",
    "\n",
    "        # We're interested in the last output for prediction,\n",
    "        # which is the contextually richest. If x has shape (batch_size, seq_len, input_dim),\n",
    "        # out will have shape (batch_size, seq_len, hidden_dim).\n",
    "        # Thus, we select out[:,-1,:] to get a shape of (batch_size, hidden_dim)\n",
    "        output = output[:, -1, :]\n",
    "\n",
    "        # GRU ouputs already went through tanh so no activation required.\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs, labels)\n",
    "        return outputs, labels, loss\n",
    "\n",
    "    def _common_log(self, outputs, labels, loss, stage: str):\n",
    "        self.log_dict({\n",
    "            f'{stage}_loss': loss,\n",
    "            f'{stage}_acc': self.accuracy(outputs, labels),\n",
    "            f'{stage}_f1': self.f1_score(outputs, labels),\n",
    "        }, prog_bar=True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self._common_step(batch, batch_idx)\n",
    "        self._common_log(outputs, labels, loss, 'train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self._common_step(batch, batch_idx)\n",
    "        self._common_log(outputs, labels, loss, 'val')\n",
    "        self.log_dict({\n",
    "            'val_hloss': self.hamming_loss(outputs, labels),\n",
    "        })\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-2)\n",
    "\n",
    "model = PredictorModel(dm.n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35d9cc54-33fb-4ac2-88b4-53b5bcc6b7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ gru          │ GRU                       │  4.1 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ fc           │ Linear                    │    297 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ accuracy     │ MultilabelAccuracy        │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ f1_score     │ MultilabelF1Score         │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ hamming_loss │ MultilabelHammingDistance │      0 │\n",
       "└───┴──────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ gru          │ GRU                       │  4.1 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ fc           │ Linear                    │    297 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ accuracy     │ MultilabelAccuracy        │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ f1_score     │ MultilabelF1Score         │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ hamming_loss │ MultilabelHammingDistance │      0 │\n",
       "└───┴──────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.4 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.4 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.4 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.4 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6df633f58d428187271a5799880b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8332593d426d4835be5d9b11be9c2de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb2e27590b64ee4a94df74b0a2318a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3aba1ca22c4ea3bda8e20921273e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c859ea32d42b40f380360530b6c5d2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b3f743710447528ed82291697204b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2489d2ad4ced452fafef5676219c73d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91bd8aaf5a04455bc026281c4226178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f82cc9af8c4e498a7570cbc732c945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe741da201444d9d84b3e804a8225312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545d6241ab2e4289aa6907d3aa0ea3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397507afb4e949d4925e8c0fcae50f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d1175fafe44b649853fcdb47413d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b7e543cd144e3b914b778616ee9781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f22b07f4bf4a3b8f568bbcb6025fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb59cef747e4529927d7cfac5edbf52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08689a757e534a9399d14b2e120c3a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4636009f7474c7fa1362454784de298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6e3c2fe24040c1a28fdd620694a113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d768e36741e14ea59d40eb10b11437ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Loop\n",
    "logger = pl.loggers.TensorBoardLogger(\"runs\", name=\"predictor\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    callbacks=[pl.callbacks.RichProgressBar(leave=True)],\n",
    "    logger=logger,\n",
    ")\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d0d134d-d543-41bf-a4f9-406738fcc468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641cad6-9755-40e7-8af5-76f791d5c655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
