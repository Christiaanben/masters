{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Introduction\n",
    "In the realm of natural language processing (NLP), the rise of transformer architectures, especially BERT (Bidirectional Encoder Representations from Transformers) and its variants, has revolutionized the field by setting new benchmarks across various tasks. One such variant, DistilBERT, offers a compact, faster, and more efficient solution without compromising too much on the performance characteristics of its larger counterpart.\r\n",
    "\r\n",
    "The objective of this study, as encapsulated within this Jupyter Notebook, is to construct a text classifier leveraging the prowess of DistilBERT. Given the intricacies and nuances associated with deep learning and NLP tasks, it's essential to rely on tools that streamline the process and make it more interpretable. To this end, we utilize PyTorch Lightningâ€”a lightweight PyTorch wrapper that simplifies the training and evaluation pipeline, allowing us to focus on the model architecture and logic rather than the boilerplate training loops.\r\n",
    "\r\n",
    "Furthermore, harnessing pretrained models has become a staple in modern NLP. It allows researchers and practitioners to leverage vast amounts of knowledge and insights distilled into these models from extensive training on large-scale datasets. The transformers library by Hugging Face offers a repository of such pretrained models, including DistilBERT, and facilitates the integration of these models into custom applications.\r\n",
    "\r\n",
    "Within this notebook, we'll journey through the stages of data preprocessing, model loading, training, evaluation, and inference. This endeavor not only stands as an exploration of state-of-the-art techniques but also as a testament to the ease and efficiency brought about by tools like PyTorch Lightning and the transformers library in the rapidly evolving landscape of NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1047e446f90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup & Configurations (constants, seeds, and devices)\n",
    "RANDOM_SEED = 69\n",
    "DATASET_FILENAME = '../data/clean/customer_support_twitter_full.json'\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation Count: 1001\n",
      "Message Count: 2619\n",
      "Label Counts:\n",
      "* Question                 : 1,180\n",
      "* URL Share                : 1,132\n",
      "* Direct to DM             :   741\n",
      "* Check Version/Details    :   561\n",
      "* Provide Information      :   514\n",
      "* Acknowledgement          :   355\n",
      "* Report Problem           :   318\n",
      "* Troubleshooting          :   217\n",
      "* Call Center Inquiry      :    18\n",
      "Sample conversation:[\n",
      "  {\n",
      "    \"id\": 698,\n",
      "    \"text\": \"@AppleSupport  URL\",\n",
      "    \"authored\": false,\n",
      "    \"intents\": [\n",
      "      \"URL Share\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 696,\n",
      "    \"text\": \"USERNAME We're here for you. Which version of the iOS are you running? Check from Settings > General > About.\",\n",
      "    \"authored\": true,\n",
      "    \"intents\": [\n",
      "      \"Question\",\n",
      "      \"Provide Information\",\n",
      "      \"Check Version/Details\",\n",
      "      \"Acknowledgement\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 697,\n",
      "    \"text\": \"@AppleSupport The newest update. I made sure to download it yesterday.\",\n",
      "    \"authored\": false,\n",
      "    \"intents\": [\n",
      "      \"Provide Information\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 699,\n",
      "    \"text\": \"USERNAME Lets take a closer look into this issue. Select the following link to join us in a DM and we'll go from there. URL\",\n",
      "    \"authored\": true,\n",
      "    \"intents\": [\n",
      "      \"Report Problem\",\n",
      "      \"Direct to DM\",\n",
      "      \"URL Share\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "with open(DATASET_FILENAME) as file:\n",
    "    conversations = json.load(file)\n",
    "\n",
    "# Extract Statistics\n",
    "n_messages = 0\n",
    "intent_counts = dict()\n",
    "for conversation in conversations:\n",
    "    for message in conversation:\n",
    "        n_messages += 1\n",
    "        for intent in message.get('intents'):\n",
    "            intent_counts[intent] = intent_counts.get(intent, 0) + 1\n",
    "ordered_counts = sorted(intent_counts.items(), key=lambda intent: intent[1], reverse= True)\n",
    "ordered_counts_text = \"\\n\".join([f\"* {k:<25}: {v:5,}\" for k, v in ordered_counts])\n",
    "\n",
    "print(f'Conversation Count: {len(conversations)}')\n",
    "print(f'Message Count: {n_messages}')\n",
    "print(f'Label Counts:\\n{ordered_counts_text}')\n",
    "print(f'Sample conversation:{json.dumps(conversations[0], indent=2)}')\n",
    "\n",
    "# Split the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 800; Val: 100; Test: 101\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 80% train, 10% validation, and 10% test\n",
    "train_data, temp_data = train_test_split(conversations, test_size=0.2, random_state=RANDOM_SEED)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=RANDOM_SEED)\n",
    "print(f'Train: {len(train_data)}; Val: {len(val_data)}; Test: {len(test_data)}')\n",
    "\n",
    "# Define PyTorch Lightning Dataset\n",
    "class ClassifierDataModule(pl.LightningDataModule):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Loading & Configuration\n",
    "class ClassifierModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
